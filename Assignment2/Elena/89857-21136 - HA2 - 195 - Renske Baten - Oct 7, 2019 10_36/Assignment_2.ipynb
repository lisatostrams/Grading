{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "## Objective of this assignment\n",
    "The objective of this assignment is to get an understanding of the many ways data can be visualized. Upon completing this exercise you should be familiar with histograms, boxplots and scatter plots.\n",
    "\n",
    "\n",
    "## ** Important: ** When handing in your homework:\n",
    "+ Hand in the notebook **and nothing else** named as follows: StudentName1_snumber_StudentName2_snumber.ipynb\n",
    "+ **From this week on, we will deduct a point if you zip/tar/archive the notebook, especially if you include the data folder!** \n",
    "+ Provide clear and complete answers to the questions below under a separate header (not hidden somewhere in your source code), and make sure to explain your answers / motivate your choices. Add Markdown cells where necessary.\n",
    "+ Source code, output graphs, derivations, etc., should be included in the notebook.\n",
    "+ Hand-in: upload to Brightspace.\n",
    "+ Include name, student number, assignment (especially in filenames)!\n",
    "+ When working in pairs only one of you should upload the assignment, and report the name of your partner in your filename.\n",
    "+ Use the Brightspace discussion board or email the student assistants for questions on how to complete the exercises.\n",
    "+ If you find mistakes/have suggestions/would like to complain about the assigment material itself, please email me [Lisa] at `l.tostrams@science.ru.nl`\n",
    "\n",
    "\n",
    "## Advised Reading and Exercise Material\n",
    "**The following reading material is recommended:**\n",
    "\n",
    "- Pang-Ning Tan, Michael Steinbach, and Vipin Kumar, *Introduction to Data Mining*, section 3.3\n",
    "- Jonathon Shlens, *A tutorial on Principal Component Analysis* , https://arxiv.org/abs/1404.1100\n",
    "\n",
    "\n",
    "## 2.1 Visualizing wine data (4.5 points)\n",
    "\n",
    "In this part of the exercise we will consider two data sets related to red and white variants of the Portuguese \"Vinho Verde\" wine[1]. The data has been downloaded from http://archive.ics.uci.edu/ml/datasets/Wine+Quality. Only physicochemical and sensory attributes are available, i.e., there is no data about grape types, wine brand, wine selling price, etc. The data has the following attributes:\n",
    "\n",
    "| #   |  Attribute      | Unit |\n",
    "| --- |:--------------- |:---- |\n",
    "| 1   | Fixed acidity (tartaric) | g/dm3 |\n",
    "| 2   | Volatile acidity (acetic) | g/dm3 |\n",
    "| 3   | Citric acid | g/dm3 |\n",
    "| 4   | Residual sugar | g/dm3 |\n",
    "| 5   | Chlorides | g/dm3 |\n",
    "| 6   | Free sulfur dioxide | mg/dm3 |\n",
    "| 7   | Total sulfur dioxide | mg/dm3 |\n",
    "| 8   | Density | g/cm3 |\n",
    "| 9   | pH | pH |\n",
    "| 10  | Sulphates | g/dm3 |\n",
    "| 11  | Alcohol | % vol. |\n",
    "| 12  | Quality score | 0-10 |\n",
    "\n",
    "Attributes 1-11 are based on physicochemical tests and attribute 12 on human judging. The data set has many observations that can be considered outliers and in order to carry out analyses it is important to remove the corrupt observations.\n",
    "\n",
    "The aim of this exercise is to use visualization to identify outliers and remove these outliers from the data. It might be necessary to remove some outliers before other outlying observations become visible. Thus, the process of finding and removing outliers is often iterative. The wine data is stored in a MATLAB file, `Data/wine.mat`\n",
    "\n",
    "*This exercise is based upon material kindly provided by the Cognitive System Section, DTU Compute,\n",
    "http://cogsys.compute.dtu.dk. Any sale or commercial distribution is strictly forbidden.*\n",
    "\n",
    "> 2.1.1a) (3pts)\n",
    "1. Load the data into Python using the `scipy.io.loadmat()` function. \n",
    "2. This data set contains many observations that can be considered outliers. Plot a box plot and a histogram for each attribute to visualize the outliers in the data set. Use subplotting to nicely visualize these plots.\n",
    "3. From prior knowledge we expect volatile acidity to be around 0-2 g/dm3, density to be close to 1 g/cm3, and alcohol percentage to be somewhere between 5-20% vol. We can safely identify the outliers for these attributes, searching for the values, which are a factor of 10 greater than the largest we expect. Identify outliers for volatile acidity, density and alcohol percentage, and remove them from the data set. This means that you should remove the entire sample from the dataset, not just for that attribute!\n",
    "4. Plot new box plots and histograms for these attributes and compare them with initial ones.\n",
    "\n",
    "> \n",
    " + *You can use the `scipy.stats.zscore()` to standardize your data before you plot a boxplot.*\n",
    " + *You can use logical indexing to easily make a new dataset (for example $X\\_filtered$, where the outliers are removed. This is much easier, and faster than methods like dropping, or selecting using a for loop or list comprehension. For more information, see: https://docs.scipy.org/doc/numpy-1.13.0/user/basics.indexing.html Take a look at the -Boolean or \"mask\" index arrays- section.*\n",
    " + *You can use the function `matplotlib.pyplot.subplots()` to plot several plots in one figure. A simple example an be found at: https://matplotlib.org/2.0.2/examples/pylab_examples/subplots_demo.html, take a look at the 2D subplot specifically. There is also an example of a subplot in the first assignment. If you're handy, you can devise a for loop which fills up the subplot area!* \n",
    " + *The object in wine.mat is a dictionary. The attributes are stored in matrix $X$. Attribute names and class names are stored in the attributeNames object, which contain arrays, of which the first element contains the names*\n",
    "\n",
    "**Make sure to take a look at the documentation of functions before you try and use them!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pyplot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-341d7e414a53>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./Data/wine.mat'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mfig1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mfig2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pyplot' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "\n",
    "data = scipy.io.loadmat('./Data/wine.mat')\n",
    "\n",
    "fig1, ax1 = pyplot.subplots(12, 2, figsize=(10,50))\n",
    "fig2, ax2 = pyplot.subplots(12, 2, figsize=(10,50))\n",
    "\n",
    "D_List = enumerate([x[0] for x in data['attributeNames'][0]])\n",
    "D = data['X']\n",
    "VolAc = D[:,1] < 20\n",
    "D_filtered = D[VolAc, :]\n",
    "\n",
    "Den = D_filtered[:, 7] < 10\n",
    "D_filtered = D_filtered[Den, :]\n",
    "\n",
    "Alc = D_filtered[:, 10] < 100\n",
    "D_filtered = D_filtered[Alc, :]\n",
    "\n",
    "for x,name in D_List:\n",
    "    ax1[x, 0].boxplot(D[:, x], '')\n",
    "    ax1[x, 0].set_title(name)\n",
    "    ax1[x, 1].hist(D[:, x], 10)\n",
    "    ax1[x, 1].set_title(name)\n",
    "\n",
    "    ax2[x, 0].boxplot(D_filtered[:, x], '')\n",
    "    ax2[x, 0].set_title(name + \" (filtered)\")\n",
    "    ax2[x, 1].hist(D_filtered[:, x], 10)\n",
    "    ax2[x, 1].set_title(name + \" (filtered)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "----\n",
    "\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 2.1.1b (0.5pts)\n",
    "Why do we need to standardize the data after removing the outliers? Give the -statistical- reason, not just the practical reason. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Standardizing data makes it more compact, thus easier to calculate with or apply transformations on. Standardizing data also stops some points from weighing more heavily than others. This precludes false results, originating from certain data points influencing the final result more than they should. But because standardizing data changes its average results, the z-score of the data will be incorrect if standardized before the removal of outliers.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 2.1.2 (1pt) Make scatter plots between attributes and wine quality as rated by human judges. Can you manually identify any clear relationship between the attributes of the wine and wine quality? Which values of these attributes are associated with high quality wine? Use the correlation coefficients to substantiate your answers. Make sure to use the data where the outliers are removed \n",
    "+ *You can calculate the correlation coefficient using the `scipy.stats.pearsonr()` function to measure the strength of association.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "----\n",
    "\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2.2 Visualizing the handwritten digits (4 points)\n",
    "\n",
    "In this part of the exercise we will analyse the famous *mnist* handwritten digit dataset from: http://yann.lecun.com/exdb/mnist/.\n",
    "\n",
    "> 2.2.1 (4pts)\n",
    "1. Load zipdata.mat by using the loadmat function. There are two data sets containing handwritten digits: *testdata* and *traindata*. Here, we will only use *traindata*. The first column in the matrix *traindata* contains the digit (class) and the last 256 columns contain the pixel values.\n",
    "2. Create the data matrix *X* and the class index vector *y* from the data. Remove\n",
    "the digits with the class index 2-9 from the data, so only digits belonging to\n",
    "the class 0 and 1 are analyzed. (remember logical indexing!) \n",
    "3. Visualize the first 10 digits as images. (take a look at the example code)\n",
    "Next, compute the principal components (PCA) of the data matrix. Now, using the PCA model, create a new data matrix $Z$ by projecting $X$ onto the space spanned by the loadings $V$. The new data matrix should have 4 attributes corresponding to PC1-PC4.  Use subplotting to show the digits and their reconstructed counterparts in an orderly manner.\n",
    "4. Reconstruct the initial data using PC1-PC4 into a new matrix called $W$. Visualize the first 10 digits as images for the reconstructed data and compare them with images for the original data.\n",
    "5. Make a 4-by-4 subplot of scatter plots of each possible combination projection onto PC1 to PC4 (contained in $Z$) against each other. You can leave the diagonal blank.  Plot elements belonging to different classes in different colors. Add a legend to clarify which digit is shown in which color.\n",
    "6. Make a 3-dimensional scatter plot of the projections onto the first three principal components PC1-PC3 (contained in $Z$). Plot elements belonging to different classes in different colors. Add a legend to clarify which digit is shown in which color.\n",
    "7. What can you conclude from the various scatterplots about the PCs and the way they separate the data?\n",
    "\n",
    "> **Hints:**\n",
    "+ *The below example code can help you visualize digits as images.*\n",
    "+ *See Assignment 1 if you can not recall how to compute a PCA.*\n",
    "+ *Keep in mind that numpy.linalg.svd() returns the transposed **V<sup>T</sup>** matrix as output.*\n",
    "+ *You can use **Z** = **Y** $*$ **V**[:,:4] to project the data onto the first four PCs. Don't forget that the $*$ operator does not perform matrix multiplication for numpy arrays!*\n",
    "+ *To reconstruct the data from projection you can use the following formula: **W** = **Z**&ast;**V**[:,:4]<sup>T</sup> + **μ**. *\n",
    "+ *You can take a look at the example_figure.ipynb notebook to see how you can easily plot multiple classes and color them correspondingly.* \n",
    "+ *It is advisable to make a for-loop to generate the 2D scatter plots, this saves a lot of time. It is an important skill to master if you want to easily modify your work later on, for example when correcting mistakes, or when you want to modify each plot in the same manner.* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example code:\n",
    "#------------------------------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from scipy.io import loadmat\n",
    "from numpy import reshape\n",
    "\n",
    "# Index of the digit to display\n",
    "i = 0\n",
    "\n",
    "# Load Matlab data file to python dict structure\n",
    "mat_data = loadmat('./Data/zipdata.mat')\n",
    "\n",
    "# Extract variables of interest\n",
    "testdata = mat_data['testdata']\n",
    "traindata = mat_data['traindata']\n",
    "X = traindata[:,1:]\n",
    "y = traindata[:,0]\n",
    "\n",
    "# Visualize the i'th digit as an image\n",
    "plt.subplot(1,1,1);\n",
    "I = reshape(X[i,:],(16,16))\n",
    "plt.imshow(I, extent=(0,16,0,16), cmap=cm.gray_r);\n",
    "plt.title('Digit as an image');\n",
    "plt.show()\n",
    "#------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "\n",
    "----\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Probability and Statistics (1.5 points)\n",
    "The aim of this exercise is to learn how to calculate basic statistics in python.\n",
    "> 2.3.1 (0.3pts) A study of a very limited population of Aliens reveals the following number of body appendages (limbs):\n",
    "<center>2,3,6,8,11,18</center>\n",
    "i. Find the mean $m$ and the standard deviation $\\sigma$ of this population.\n",
    "+ *You can use the methods numpy.ndarray.mean() and numpy.ndarray.std() to calculate the mean and standard deviation.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import array as arr\n",
    "\n",
    "array = np.array([2, 3, 6, 8, 11, 18])\n",
    "M = np.ndarray.mean(array)\n",
    "σ = np.ndarray.std(array)\n",
    "\n",
    "print(\"Mean m of this population is\", M)\n",
    "print(\"Standard deviation σ of this population is\", σ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ii. (0.3pts) List all possible samples of two aliens without replacement, and find each mean. Do the same with samples of four aliens.\n",
    "+ *You can use the method itertools.combinations(v,n) to find all possible samples of a vector v taking n elements at a time.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "import numpy as np\n",
    "\n",
    "limbs = [2, 3, 4, 8, 11, 18]\n",
    "combi2 = []\n",
    "combi4 = []\n",
    "\n",
    "groupsOf2 = [list(x) for x in it.combinations(limbs, 2)]\n",
    "combi2.extend(groupsOf2)\n",
    "\n",
    "array1 = np.asarray(combi2)\n",
    "\n",
    "groupsOf4 = [list(y) for y in it.combinations(limbs, 4)]\n",
    "combi4.extend(groupsOf4)\n",
    "\n",
    "array2 = np.asarray(combi4)\n",
    " \n",
    "print(\"Possible combinations of aliens in groups of 2: \")\n",
    "print(combi2)\n",
    "print(\"The means of combinations of aliens in groups of 2 are\")\n",
    "for i in range(0, len(array1)):\n",
    "    print(np.ndarray.mean(array1[i]))\n",
    "\n",
    "print(\"Possible combinations of aliens in groups of 4: \")\n",
    "print(combi4)\n",
    "print(\"The means of combinations of aliens in groups of 4 are\")\n",
    "for i in range(0, len(array2)):\n",
    "    print(np.ndarray.mean(array2[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> iii. (0.3pts) Each of the means above is called a sample mean. Find the mean of all the sample means (denoted by $m_x$) and the standard\n",
    "deviation of all the sample means (denoted by $\\sigma_x$) for both\n",
    "the *N=2* and *N=4* samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "MeansN2 = np.array([2.5, 3.0, 5.0, 6.5, 10.0, 3.5, 5.5, 7.0, 10.5, 6.0, 7.5, 11.0, 9.5, 13.0, 14.5])\n",
    "TotalMeanN2 = np.ndarray.mean(MeansN2)\n",
    "TotalDevN2 = np.ndarray.std(MeansN2)\n",
    "\n",
    "MeansN4 = np.array([4.25, 5.0, 6.75, 6.0, 7.75, 8.5, 6.25, 8.0, 8.75, 9.75, 6.5, 8.25, 9.0, 10.0, 10.25])\n",
    "TotalMeanN4 = np.ndarray.mean(MeansN4)\n",
    "TotalDevN4 = np.ndarray.std(MeansN4)\n",
    "\n",
    "print(\"The total mean Mx of all samples of N=2 is \")\n",
    "print(TotalMeanN2)\n",
    "print(\"The standard deviation 𝜎x of all means of N=2 is \")\n",
    "print(TotalDevN2)\n",
    "\n",
    "print(\"The total mean Mx of all samples of N=4 is \")\n",
    "print(TotalMeanN4)\n",
    "print(\"The standard deviation 𝜎x of all means of N=4 is \")\n",
    "print(TotalDevN4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> iv. Verify the Central Limit Theorem: (i) (0.1pts) compare the population\n",
    "mean with the mean of both sample means; (ii) (0.2pts) compare the population\n",
    "standard deviation divided by the square root of the sample size\n",
    "with the standard deviation of both sample means (i.e., does\n",
    "$\\sigma_x \\approx \\sigma/\\sqrt{N}$). BTW, a better approximation for\n",
    "small population sizes is $\\sigma_x = \\sigma / \\sqrt{N} \\times\n",
    "\\sqrt{(M-N)/(M-1)}$ with *M = 6* the size of the original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> v. (0.3pts) Plot the distribution of the population and the distributions of both sample means using histograms. What happens to the shape of the sample means distribution as the sample size (N*) increases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "\n",
    "----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
