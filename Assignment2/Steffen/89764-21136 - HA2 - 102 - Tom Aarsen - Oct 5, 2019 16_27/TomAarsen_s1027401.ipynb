{"cells":[{"cell_type":"markdown","source":[" # Assignment 2, by Tom Aarsen, s1027401\n","\n"," ## Objective of this assignment\n"," The objective of this assignment is to get an understanding of the many ways data can be visualized. Upon completing this exercise you should be familiar with histograms, boxplots and scatter plots.\n","\n","\n"," ## ** Important: ** When handing in your homework:\n"," + Hand in the notebook **and nothing else** named as follows: StudentName1_snumber_StudentName2_snumber.ipynb\n"," + **From this week on, we will deduct a point if you zip/tar/archive the notebook, especially if you include the data folder!**\n"," + Provide clear and complete answers to the questions below under a separate header (not hidden somewhere in your source code), and make sure to explain your answers / motivate your choices. Add Markdown cells where necessary.\n"," + Source code, output graphs, derivations, etc., should be included in the notebook.\n"," + Hand-in: upload to Brightspace.\n"," + Include name, student number, assignment (especially in filenames)!\n"," + When working in pairs only one of you should upload the assignment, and report the name of your partner in your filename.\n"," + Use the Brightspace discussion board or email the student assistants for questions on how to complete the exercises.\n"," + If you find mistakes/have suggestions/would like to complain about the assigment material itself, please email me [Lisa] at `l.tostrams@science.ru.nl`\n","\n","\n"," ## Advised Reading and Exercise Material\n"," **The following reading material is recommended:**\n","\n"," - Pang-Ning Tan, Michael Steinbach, and Vipin Kumar, *Introduction to Data Mining*, section 3.3\n"," - Jonathon Shlens, *A tutorial on Principal Component Analysis* , https://arxiv.org/abs/1404.1100\n","\n","\n"," ## 2.1 Visualizing wine data (4.5 points)\n","\n"," In this part of the exercise we will consider two data sets related to red and white variants of the Portuguese \"Vinho Verde\" wine[1]. The data has been downloaded from http://archive.ics.uci.edu/ml/datasets/Wine+Quality. Only physicochemical and sensory attributes are available, i.e., there is no data about grape types, wine brand, wine selling price, etc. The data has the following attributes:\n","\n"," | #   |  Attribute      | Unit |\n"," | --- |:--------------- |:---- |\n"," | 1   | Fixed acidity (tartaric) | g/dm3 |\n"," | 2   | Volatile acidity (acetic) | g/dm3 |\n"," | 3   | Citric acid | g/dm3 |\n"," | 4   | Residual sugar | g/dm3 |\n"," | 5   | Chlorides | g/dm3 |\n"," | 6   | Free sulfur dioxide | mg/dm3 |\n"," | 7   | Total sulfur dioxide | mg/dm3 |\n"," | 8   | Density | g/cm3 |\n"," | 9   | pH | pH |\n"," | 10  | Sulphates | g/dm3 |\n"," | 11  | Alcohol | % vol. |\n"," | 12  | Quality score | 0-10 |\n","\n"," Attributes 1-11 are based on physicochemical tests and attribute 12 on human judging. The data set has many observations that can be considered outliers and in order to carry out analyses it is important to remove the corrupt observations.\n","\n"," The aim of this exercise is to use visualization to identify outliers and remove these outliers from the data. It might be necessary to remove some outliers before other outlying observations become visible. Thus, the process of finding and removing outliers is often iterative. The wine data is stored in a MATLAB file, `Data/wine.mat`\n","\n"," *This exercise is based upon material kindly provided by the Cognitive System Section, DTU Compute,\n"," http://cogsys.compute.dtu.dk. Any sale or commercial distribution is strictly forbidden.*\n","\n"," > 2.1.1a) (3pts)\n"," 1. Load the data into Python using the `scipy.io.loadmat()` function.\n"," 2. This data set contains many observations that can be considered outliers. Plot a box plot and a histogram for each attribute to visualize the outliers in the data set. Use subplotting to nicely visualize these plots.\n"," 3. From prior knowledge we expect volatile acidity to be around 0-2 g/dm3, density to be close to 1 g/cm3, and alcohol percentage to be somewhere between 5-20% vol. We can safely identify the outliers for these attributes, searching for the values, which are a factor of 10 greater than the largest we expect. Identify outliers for volatile acidity, density and alcohol percentage, and remove them from the data set. This means that you should remove the entire sample from the dataset, not just for that attribute!\n"," 4. Plot new box plots and histograms for these attributes and compare them with initial ones.\n","\n"," >\n","  + *You can use the `scipy.stats.zscore()` to standardize your data before you plot a boxplot.*\n","  + *You can use logical indexing to easily make a new dataset (for example $X\\_filtered$, where the outliers are removed. This is much easier, and faster than methods like dropping, or selecting using a for loop or list comprehension. For more information, see: https://docs.scipy.org/doc/numpy-1.13.0/user/basics.indexing.html Take a look at the -Boolean or \"mask\" index arrays- section.*\n","  + *You can use the function `matplotlib.pyplot.subplots()` to plot several plots in one figure. A simple example an be found at: https://matplotlib.org/2.0.2/examples/pylab_examples/subplots_demo.html, take a look at the 2D subplot specifically. There is also an example of a subplot in the first assignment. If you're handy, you can devise a for loop which fills up the subplot area!*\n","  + *The object in wine.mat is a dictionary. The attributes are stored in matrix $X$. Attribute names and class names are stored in the attributeNames object, which contain arrays, of which the first element contains the names*\n","\n"," **Make sure to take a look at the documentation of functions before you try and use them!**\n",""],"metadata":{}},{"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import scipy.io as sio\n","import scipy.stats as sstats\n","# Load Data, and extract Matrix X\n","data_dict = sio.loadmat(\"Data/wine.mat\")\n","X = data_dict[\"X\"]\n","attributes = [attr[0] for attr in data_dict[\"attributeNames\"][0]]\n","\n","def create_plot(plot_data):\n","    # Create plot\n","    f, axarr = plt.subplots(2, 12)\n","    f.subplots_adjust(wspace=1, hspace=0.1)\n","    f.suptitle(\"Boxplots and Histograms for each Attribute\")\n","\n","    # Iterate over attributes\n","    for index, attr in enumerate(attributes):\n","        # Data for this attribute only.\n","        attr_data = plot_data[:, index]\n","        standard_attr_data = sstats.zscore(attr_data)\n","\n","        # Boxplot:\n","        axarr[0, index].boxplot(standard_attr_data)\n","        #axarr[0, index].set_title(f\"{attr}\", rotation='vertical', x=-0.5, y=0.5)\n","        #axarr[0, index].set_title(f\"{attr}\", rotation=10, fontsize=12)\n","        axarr[0, index].set_title(f\"{attr}\", fontsize=12, y=(1.05 if index % 2 == 0 else 1))\n","        \n","        # Histogram:\n","        axarr[1, index].hist(attr_data)\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","create_plot(X)\n","\n","# Filter Volatile Acidity\n","X_filtered = X[X[:, 1] < 20]\n","# Filter Density\n","X_filtered = X_filtered[X_filtered[:, 7] < 10]\n","# Filter Alcohol\n","X_filtered = X_filtered[X_filtered[:, 10] < 200]\n","\n","create_plot(X_filtered)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ----\n"," After filtering the three attributes, the size of the boxes in the box plots increase greatly, no longer tiny due to outliers.\n"," Similary, the histogram plots considerably more gradual now, as they no longer set the maximum value to be very high. Before this filtering, these three attribute their histogram were just a single line on the left, with essentially all values, and very few outlier values on the right of the histogram chart.\n"," There was no information to be gained from this single line, but there is useful information in the filtered chart.\n"," ----"],"metadata":{}},{"cell_type":"markdown","source":[" > 2.1.1b (0.5pts)\n"," Why do we need to standardize the data after removing the outliers? Give the -statistical- reason, not just the practical reason."],"metadata":{}},{"cell_type":"markdown","source":[" ----\n"," If we standardize the data before removing outliers, then the final data will still be standardized as if the outliers are normal values. This likely means that most, if not all, of the data is in an extreme, and improperly scaled compared to if we remove outliers before standardizing.\n","\n"," ----"],"metadata":{}},{"cell_type":"markdown","source":[" > 2.1.2 (1pt) Make scatter plots between attributes and wine quality as rated by human judges. Can you manually identify any clear relationship between the attributes of the wine and wine quality? Which values of these attributes are associated with high quality wine? Use the correlation coefficients to substantiate your answers. Make sure to use the data where the outliers are removed\n"," + *You can calculate the correlation coefficient using the `scipy.stats.pearsonr()` function to measure the strength of association.*"],"metadata":{}},{"source":["\n","f, axarr = plt.subplots(4, 3)\n","f.suptitle(\"Wine Quality vs Attributes\\ny axis is Wine Quality\")\n","for index, attr in enumerate(attributes[:-1]):\n","    # Get x and y\n","    x = X_filtered[:, index]\n","    y = X_filtered[:, 11]\n","    # Plot scatter\n","    axarr[index % 4, index // 4].scatter(x, y)\n","    # Plot the best line fit through the data\n","    axarr[index % 4, index // 4].plot(np.unique(x), np.poly1d(np.polyfit(x, y, 1))(np.unique(x)), 'r')\n","    axarr[index % 4, index // 4].set_title(attr)\n","\n","    cc = sstats.pearsonr(x, y)\n","    print(attr, cc)\n","\n","plt.tight_layout()\n","plt.show()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ----\n"," The red line through the scatter data effectively shows the correlation between the attribute and the wine quality. If the line goes up, then there is a positive correlation between the wine quality and the attribute, while if the line goes down, there's a negative one.\n"," As can be seen by these lines, and also the correlation data, Alcohol has the best correlation. Beyond that, Free sulfur dioxide and Citric Acid have a correlation such that \"more is better\".\n"," Some other attributes, such as density, chlorides or volatile acidity have an opposite correlation, where \"less is better\".\n"," ----"],"metadata":{}},{"cell_type":"markdown","source":[" ## 2.2 Visualizing the handwritten digits (4 points)\n","\n"," In this part of the exercise we will analyse the famous *mnist* handwritten digit dataset from: http://yann.lecun.com/exdb/mnist/.\n","\n"," > 2.2.1 (4pts)\n"," 1. Load zipdata.mat by using the loadmat function. There are two data sets containing handwritten digits: *testdata* and *traindata*. Here, we will only use *traindata*. The first column in the matrix *traindata* contains the digit (class) and the last 256 columns contain the pixel values.\n"," 2. Create the data matrix *X* and the class index vector *y* from the data. Remove\n"," the digits with the class index 2-9 from the data, so only digits belonging to\n"," the class 0 and 1 are analyzed. (remember logical indexing!)\n"," 3. Visualize the first 10 digits as images. (take a look at the example code)\n"," Next, compute the principal components (PCA) of the data matrix. Now, using the PCA model, create a new data matrix $Z$ by projecting $X$ onto the space spanned by the loadings $V$. The new data matrix should have 4 attributes corresponding to PC1-PC4.  Use subplotting to show the digits and their reconstructed counterparts in an orderly manner.\n"," 4. Reconstruct the initial data using PC1-PC4 into a new matrix called $W$. Visualize the first 10 digits as images for the reconstructed data and compare them with images for the original data.\n"," 5. Make a 4-by-4 subplot of scatter plots of each possible combination projection onto PC1 to PC4 (contained in $Z$) against each other. You can leave the diagonal blank.  Plot elements belonging to different classes in different colors. Add a legend to clarify which digit is shown in which color.\n"," 6. Make a 3-dimensional scatter plot of the projections onto the first three principal components PC1-PC3 (contained in $Z$). Plot elements belonging to different classes in different colors. Add a legend to clarify which digit is shown in which color.\n"," 7. What can you conclude from the various scatterplots about the PCs and the way they separate the data?\n","\n"," > **Hints:**\n"," + *The below example code can help you visualize digits as images.*\n"," + *See Assignment 1 if you can not recall how to compute a PCA.*\n"," + *Keep in mind that numpy.linalg.svd() returns the transposed **V<sup>T</sup>** matrix as output.*\n"," + *You can use **Z** = **Y** $*$ **V**[:,:4] to project the data onto the first four PCs. Don't forget that the $*$ operator does not perform matrix multiplication for numpy arrays!*\n"," + *To reconstruct the data from projection you can use the following formula: **W** = **Z**&ast;**V**[:,:4]<sup>T</sup> + **μ**. *\n"," + *You can take a look at the example_figure.ipynb notebook to see how you can easily plot multiple classes and color them correspondingly.*\n"," + *It is advisable to make a for-loop to generate the 2D scatter plots, this saves a lot of time. It is an important skill to master if you want to easily modify your work later on, for example when correcting mistakes, or when you want to modify each plot in the same manner.*\n",""],"metadata":{}},{"source":["## Example code:\n","#------------------------------------------------\n","\"\"\"\n","import matplotlib.pyplot as plt\n","import matplotlib.cm as cm\n","from scipy.io import loadmat\n","from numpy import reshape\n","\n","# Index of the digit to display\n","i = 0\n","\n","# Load Matlab data file to python dict structure\n","mat_data = loadmat('./Data/zipdata.mat')\n","\n","# Extract variables of interest\n","testdata = mat_data['testdata']\n","traindata = mat_data['traindata']\n","plot_data = traindata[:,1:]\n","y = traindata[:,0]\n","\n","# Visualize the i'th digit as an image\n","plt.subplot(1,1,1)\n","I = reshape(plot_data[i,:],(16,16))\n","plt.imshow(I, extent=(0,16,0,16), cmap=cm.gray_r)\n","plt.title('Digit as an image')\n","plt.show()\n","\"\"\"\n","#------------------------------------------------\n","## No longer Example code:\n","\n","import matplotlib.cm as cm\n","\n","def display(X, W, y, i):\n","    f, axarr = plt.subplots(1, 2)\n","    f.suptitle(f'{y[i]:.0f} as an image')\n","    #plt.subplot(1,1,1)\n","    for index, data in enumerate([X, W]):\n","        I = np.reshape(data[i,:],(16,16))\n","        axarr[index].imshow(I, extent=(0,16,0,16), cmap=cm.gray_r)\n","        axarr[index].set_title([\"Before PCA\", \"After PCA\"][index])\n","    plt.show()\n","\n","mat_data = sio.loadmat('./Data/zipdata.mat')\n","# Get traindata\n","traindata = mat_data[\"traindata\"]\n","# Filter it, only consider 0 and 1\n","traindata = traindata[traindata[:,0] < 2]\n","# y is the first column, X the rest\n","y = traindata[:, 0]\n","X = traindata[:, 1:]\n","\n","# Apply the first 4 PCAs to X.\n","# Mean\n","m = X.mean(axis=0)\n","# Center the data\n","X_centered = X - m\n","# Calculate SVD\n","U,sv,Vt = np.linalg.svd(X)\n","V = Vt.T\n","# Create Z using X and the first 4 PCA's\n","Z = np.dot(X, V[:,:4])\n","# Reconstruct the original data\n","W = Z.dot(V[:,:4].T)\n","\n","# Display the original first 10 digits, next to the \"reduced\" first 10 digits\n","for i in range(10):\n","    display(X, W, y, i)\n","\n","f, axarr = plt.subplots(4, 4)\n","f.suptitle(\"Matrix plot of each attribute of Z\")\n","for x_index in range(4):\n","    for y_index in range(4):\n","        if x_index == y_index:\n","            continue\n","        p0 = axarr[x_index, y_index].scatter(Z[:, x_index][y==0], Z[:, y_index][y==0])\n","        p1 = axarr[x_index, y_index].scatter(Z[:, x_index][y==1], Z[:, y_index][y==1])\n","        #axarr[x_index, y_index].scatter(X.dot(V[:, x_index])[y==0], X.dot(V[:, y_index])[y==0])\n","        #axarr[x_index, y_index].scatter(X.dot(V[:, x_index])[y==1], X.dot(V[:, y_index])[y==1])\n","        axarr[x_index, y_index].set_title(f\"PCA{x_index+1:.0f} to PCA{y_index+1:.0f}\")\n","\n","f.legend([p0, p1], labels=[\"Digit 0\", \"Digit 1\"], title=\"Legend\", loc=\"upper left\")\n","\n","plt.tight_layout()\n","plt.show()\n","\n","from mpl_toolkits.mplot3d import Axes3D\n","\n","fig = plt.figure()\n","ax = fig.add_subplot(111, projection=\"3d\")\n","ax.scatter(Z[:,0][y==0], Z[:,1][y==0],Z[:,2][y==0])\n","ax.scatter(Z[:,0][y==1], Z[:,1][y==1],Z[:,2][y==1])\n","fig.legend([p0, p1], labels=[\"Digit 0\", \"Digit 1\"], title=\"Legend\", loc=\"upper left\")\n","\n","plt.tight_layout()\n","plt.show()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ----\n"," From the scatterplots it becomes clear that the PCAs group the digits seperately, even though they are never told which information represents which digit.\n",""],"metadata":{}},{"cell_type":"markdown","source":[" ## 2.3 Probability and Statistics (1.5 points)\n"," The aim of this exercise is to learn how to calculate basic statistics in python.\n"," > 2.3.1 (0.3pts) A study of a very limited population of Aliens reveals the following number of body appendages (limbs):\n"," <center>2,3,6,8,11,18</center>\n"," i. Find the mean $m$ and the standard deviation $\\sigma$ of this population.\n"," + *You can use the methods numpy.ndarray.mean() and numpy.ndarray.std() to calculate the mean and standard deviation.*"],"metadata":{}},{"source":["data = np.array([2, 3, 6, 8, 11, 18])\n","mean = data.mean()\n","stdev = data.std()\n","\n","print(f\"Data: {data}\")\n","print(f\"Mean: {mean:.2f}\")\n","print(f\"Standard Deviation: {stdev:.6f}\")\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" The mean is 8, and the standard deviation is 5.385164807134504..."],"metadata":{}},{"cell_type":"markdown","source":[" > ii. (0.3pts) List all possible samples of two aliens without replacement, and find each mean. Do the same with samples of four aliens.\n"," + *You can use the method itertools.combinations(v,n) to find all possible samples of a vector v taking n elements at a time.*"],"metadata":{}},{"source":["import itertools\n","from functools import reduce\n","\n","def get_means(n):\n","    arr = np.array(list(itertools.combinations(data, n)))\n","    return arr.mean(axis=1)\n","\n","means_2 = get_means(2)\n","means_4 = get_means(4)\n","\n","print(\"Means, 2:\", means_2)\n","print(\"Means, 4:\", means_4)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" > iii. (0.3pts) Each of the means above is called a sample mean. Find the mean of all the sample means (denoted by $m_x$) and the standard\n"," deviation of all the sample means (denoted by $\\sigma_x$) for both\n"," the *N=2* and *N=4* samples."],"metadata":{}},{"source":["def get_mean_stdev(arr):\n","    return arr.mean(), arr.std()\n","\n","means_2_mean, means_2_stdev = get_mean_stdev(means_2)\n","means_4_mean, means_4_stdev = get_mean_stdev(means_4)\n","\n","print(\"N=2 mean:\", means_2_mean, \"stdev:\", means_2_stdev)\n","print(\"N=4 mean:\", means_4_mean, \"stdev:\", means_4_stdev)\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":["\n"," N=2 mean: 8.0 stdev: 3.40587727318528\n"," N=4 mean: 8.0 stdev: 1.70293863659264\n",""],"metadata":{}},{"cell_type":"markdown","source":[" > iv. Verify the Central Limit Theorem: (i) (0.1pts) compare the population\n"," mean with the mean of both sample means; (ii) (0.2pts) compare the population\n"," standard deviation divided by the square root of the sample size\n"," with the standard deviation of both sample means (i.e., does\n"," $\\sigma_x \\approx \\sigma/\\sqrt{N}$). BTW, a better approximation for\n"," small population sizes is $\\sigma_x = \\sigma / \\sqrt{N} \\times\n"," \\sqrt{(M-N)/(M-1)}$ with *M = 6* the size of the original"],"metadata":{}},{"cell_type":"markdown","source":[" ----\n"," Population mean = 8, both sample means: 8 and 8\n"," So, the mean is the same\n","\n"," 5.385164807134504 / sqrt(6) * sqrt(6 - 6) = 2.19848432637882\n"," This is inbetween the two sample standard deviations: 1.7029 and 3.4059\n"," ----"],"metadata":{}},{"cell_type":"markdown","source":[" > v. (0.3pts) Plot the distribution of the population and the distributions of both sample means using histograms. What happens to the shape of the sample means distribution as the sample size (N*) increases?"],"metadata":{}},{"source":["\n","plt.hist(data)\n","plt.title(\"Population distribution\")\n","plt.show()\n","plt.hist(means_2)\n","plt.title(\"Sample distribution, n=2\")\n","plt.show()\n","plt.hist(means_4)\n","plt.title(\"Sample distribution, n=4\")\n","plt.show()\n","\n","def get_new_means(n):\n","    arr = np.array(list(itertools.combinations(data.repeat(2) , n)))\n","    return arr.mean(axis=1)\n","\n","plt.hist(get_new_means(2))\n","plt.title(\"Sample distribution, n=2, sample size repeated 2 times\")\n","plt.show()\n","plt.hist(get_new_means(4))\n","plt.title(\"Sample distribution, n=4, sample size repeated 2 times\")\n","plt.show()\n","\n","#for n in range(1, 7):\n","#    plt.hist(get_means(n))\n","#    plt.title(f\"Sample distribution, n={n}\")\n","#    plt.show()\n",""],"cell_type":"code","outputs":[],"metadata":{},"execution_count":0},{"cell_type":"markdown","source":[" ----\n"," The sample distribution histograms seem to smooth out a bit. However, they don't seem to match with the population distribution all that much.\n","\n"," ----"],"metadata":{}}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}