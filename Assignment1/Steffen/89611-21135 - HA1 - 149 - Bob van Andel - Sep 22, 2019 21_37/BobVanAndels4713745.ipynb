{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "\n",
    "## Objective of this assignment\n",
    "The objective is to get acquainted with the Python language, with emphasis on its scientific and numerical extensions, how data can be imported from other data sources, the linear algebra basics that are needed for this course, visualization using principal component analysis (PCA) and the concept of similarity. Upon completing this exercise it is expected that you:\n",
    "\n",
    "- Understand how data can be represented as vectors and matrices in numerical Python (NumPy).\n",
    "- Can apply and interpret principal component analysis (PCA) for data visualization.\n",
    "- Understand the various measures of similarity such as Jaccard and Cosine similarity and apply similarity measures to query for similar observations.\n",
    "\n",
    "## ** Important: ** When handing in your homework:\n",
    "+ Hand in the notebook (and nothing else) named as follows: `StudentName1_snumber_StudentName2_snumber.ipynb`\n",
    "+ Provide clear and complete answers to the questions below under a separate header (not hidden somewhere in your source code), and make sure to explain your answers / motivate your choices. Add Markdown cells where necessary.\n",
    "+ Source code, output graphs, derivations, etc., should be included in the notebook.\n",
    "+ Hand-in: upload to Brightspace.\n",
    "+ Include name, student number, assignment (especially in filenames)!\n",
    "+ When working in pairs only one of you should upload the assignment, and report the name of your partner in your filename.\n",
    "+ Use the Brightspace discussion board or email the student assistants for questions on how to complete the exercises.\n",
    "+ If you find mistakes/have suggestions/would like to complain about the assigment material itself, please email me [Lisa] at `l.tostrams@science.ru.nl`\n",
    "\n",
    "\n",
    "## Advised Reading and Exercise Material\n",
    "**The following on-line materials are recommended:**\n",
    "\n",
    "- <http://docs.python.org/tutorial> - Introduction into Python environment, syntax and data structures. Recommended reading - sections 1, 2, 3, 4 and 5.\n",
    "- <https://docs.scipy.org/doc/numpy/user/quickstart.html> - Tutorial introducing the scientific computing in Python, array and matrix operations, indexing and slicing matrices.\n",
    "- <https://docs.scipy.org/doc/numpy/user/numpy-for-matlab-users.html> - Useful reference to scientific computing in Python if you have previous experience with MATLAB programming.\n",
    "- <https://www.datacamp.com/courses/intro-to-python-for-data-science> - Simple introduction to Data Science using Python.\n",
    "- <https://matplotlib.org/> - Documentation and examples related to matplotlib module, which we shall use extensively through the course to visualize data and results.\n",
    "- Pang-Ning Tan, Michael Steinbach, and Vipin Kumar, **Introduction to Data Mining**, sections 2.1-2.3 + (A) + B.1\n",
    "- Pang-Ning Tan, Michael Steinbach, and Vipin Kumar, **Introduction to Data Mining**, sections 2.4 + 3.1-3.2 + C.1-C.2\n",
    "\n",
    "\n",
    "## 1.1 Python and Linear Algebra basics\n",
    "\n",
    "**For this course we advise to only use NumPy ndarrays to represent vectors and matrices. The numpy.matrix data type, although intuitive, is less supported and uses operators for multiplication differently. This means that you can't perform matrix multiplications symbollically, but that you will have to use functions from the NumPy library!** \n",
    "\n",
    "**1.1.1** a)(0.3 points) Generate (and print) the following vectors using functions from the *NumPy* package in Python: \n",
    "*Note: You do not have to print column vectors as columns!*\n",
    "\n",
    "\\begin{equation}\n",
    "     \\textbf{x} = \\begin{pmatrix} \n",
    "         6 \\\\\n",
    "         7 \\\\\n",
    "         8 \\\\\n",
    "         9 \\\\\n",
    "         10 \\\\\n",
    "         11 \\\\\n",
    "         12\n",
    "       \\end{pmatrix}\n",
    "     \\textbf{y} = \\begin{pmatrix} \n",
    "         3 \\\\\n",
    "         7 \\\\\n",
    "         11 \\\\\n",
    "         15 \\\\\n",
    "         19 \\\\\n",
    "         23 \\\\\n",
    "         27\n",
    "       \\end{pmatrix}\n",
    "     \\textbf{w} = \\begin{pmatrix} \n",
    "         1 \\\\\n",
    "         1 \\\\\n",
    "         0 \\\\\n",
    "         0.5 \\\\\n",
    "         1 \\\\\n",
    "         1.5 \\\\\n",
    "         2 \\\\\n",
    "         0 \\\\\n",
    "         0 \n",
    "       \\end{pmatrix}\n",
    "     \\textbf{s} = \\begin{pmatrix}\n",
    "         100 \\\\\n",
    "         98.8 \\\\\n",
    "         97.6 \\\\\n",
    "         96.4 \\\\\n",
    "         95.2\n",
    "       \\end{pmatrix} \n",
    "     \\textbf{z} = \\begin{pmatrix}\n",
    "         0.7 \\\\\n",
    "         1.0 \\\\\n",
    "         1.3 \\\\\n",
    "         1.6 \\\\\n",
    "         1.9 \\\\\n",
    "         2.2 \\\\\n",
    "         2.5 \\\\\n",
    "         2.8\n",
    "       \\end{pmatrix}\n",
    "  \\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import NumPy\n",
    "import numpy as np\n",
    "#You'll have to manually import libraries in the future!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6  7  8  9 10 11 12]\n",
      "[ 3  7 11 15 19 23 27]\n",
      "[1.  1.  0.  0.5 1.  1.5 2.  0.  0. ]\n",
      "[100.   98.8  97.6  96.4  95.2]\n",
      "[0.7 1.  1.3 1.6 1.9 2.2 2.5 2.8]\n"
     ]
    }
   ],
   "source": [
    "##Generate the vectors in  using Python and NumPy \n",
    "x = np.array([6, 7, 8 ,9, 10 ,11, 12])\n",
    "y = np.array([3, 7, 11 ,15, 19 ,23, 27])\n",
    "w = np.array([1, 1, 0, 0.5, 1, 1.5, 2, 0, 0])\n",
    "s = np.array([100, 98.8, 97.6, 96.4, 95.2])\n",
    "z = np.array([0.7, 1.0, 1.3, 1.6, 1.9, 2.2, 2.5, 2.8])\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "print(w)\n",
    "print(s)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then compute the following operations:\n",
    "> b) (0.2 points) **v** = 3**x** + **y**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21 28 35 42 49 56 63]\n"
     ]
    }
   ],
   "source": [
    "##Answer to question 1.1.1b\n",
    "v = 3*x+y\n",
    "print(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> c) (0.2 points) The dot product between **x** and **y** and name it **q**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1057\n"
     ]
    }
   ],
   "source": [
    "##Answer to question 1.1.1c\n",
    "q = np.dot(x, y)\n",
    "print(q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> d) (0.2 points) **t** = pi(**s** + 4) (element wise multiplication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[326.72563597 322.95572479 319.1858136  315.41590242 311.64599124]\n"
     ]
    }
   ],
   "source": [
    "##Answer to question 1.1.1d\n",
    "import math\n",
    "t = math.pi*(s+4)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> e) (0.2 points) **z** = **z** - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.3  0.   0.3  0.6  0.9  1.2  1.5  1.8]\n"
     ]
    }
   ],
   "source": [
    "##Answer to question 1.1.1e\n",
    "z = z-1\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> f) (0.2 points) replace some values of x, such that the last three values in the vector are 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 4 4 4 4 4 4]\n"
     ]
    }
   ],
   "source": [
    "##Answer to question 1.1.1f\n",
    "for c in range(len(x)):\n",
    "    x[c] = 4\n",
    "    \n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> g) (0.2 points) **r** = 2**w** - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3. -3. -5. -4. -3. -2. -1. -5. -5.]\n"
     ]
    }
   ],
   "source": [
    "##Answer to question 1.1.1g\n",
    "r = 2*w-5\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.1.2** (0.25 points) Generate these matrices:\n",
    "\n",
    "\\begin{equation}\n",
    "     \\textbf{M} = \\begin{pmatrix} \n",
    "         1 & 2 & 3 \\\\\n",
    "         6 & 8 & 4 \\\\\n",
    "         6 & 7 & 5          \n",
    "         \\end{pmatrix}\n",
    "     \\textbf{N} = \\begin{pmatrix} \n",
    "         4 & 6 \\\\\n",
    "         7 & 2 \\\\\n",
    "         5 & 1\n",
    "         \\end{pmatrix}\n",
    "     \\textbf{P} = \\begin{pmatrix} \n",
    "         2 & 5 \\\\\n",
    "         5 & 5 \n",
    "         \\end{pmatrix}   \n",
    "\\end{equation}\n",
    "\n",
    "Afterwards try and compute the operations for subquestions *a* up to and including *e* and print the resulting matrix. If some operations yield errors, give the reason as to why that happens.\n",
    "\n",
    "*A hint: NumPy has functions for matrix operations you can, and should, use! For instance, * **M\\*N** * should be calculated with NumPy's `dot` product.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [6 8 4]\n",
      " [6 7 5]]\n",
      "[[4 6]\n",
      " [7 2]\n",
      " [5 1]]\n",
      "[[2 5]\n",
      " [5 5]]\n"
     ]
    }
   ],
   "source": [
    "##Generate the matrices using Python and NumPy\n",
    "M = np.array ([[1, 2, 3], [6, 8, 4], [6, 7, 5]])\n",
    "N = np.array([[4, 6], [7, 2], [5, 1]])\n",
    "P = np.array([[2, 5], [5, 5]])\n",
    "print(M)\n",
    "print(N)\n",
    "print(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> a. (0.2 points) **A** = **MN** + **N**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 37  19]\n",
      " [107  58]\n",
      " [103  56]]\n"
     ]
    }
   ],
   "source": [
    "##Answer to question 1.1.2a\n",
    "A = np.add(N, np.dot(M, N))\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> b. (0.2 points) **B** = **N**<sup>T</sup>**M**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[76 99 65]\n",
      " [24 35 31]]\n"
     ]
    }
   ],
   "source": [
    "##Answer to question 1.1.2b\n",
    "B = np.dot((N.transpose()), M)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> c. (0.2 points) **C** = **P**<sup>-1</sup> + **P**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.66666667 5.33333333]\n",
      " [5.33333333 4.86666667]]\n"
     ]
    }
   ],
   "source": [
    "##Answer to question 1.1.2c\n",
    "C = np.add (np.linalg.inv(P), P)\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> d. (0.2 points) **D** = **AC**(**C** + **B**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 2x2 matrix C cannot be added to the 2x3 matrix B\n"
     ]
    }
   ],
   "source": [
    "##Answer to question 1.1.2d\n",
    "var1 = np.dot(A, C)\n",
    "#var2 = np.add(C, B)\n",
    "#D = np.dot(var1, var2)\n",
    "#print(D)\n",
    "print(\"the 2x2 matrix C cannot be added to the 2x3 matrix B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> e. (0.2 points) Compute the eigenvalues and eigenvectors of **M**, **N**, and **P** (and print them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For M and P\n",
      "Eigenvalues [-1.26208735 14.26208735  1.        ]\n",
      "Eigenvectors [[-0.84234218  0.25759308  0.51507875]\n",
      " [ 0.38109032  0.68324439 -0.71318597]\n",
      " [ 0.38109032  0.68324439  0.47545731]]\n",
      "Eigenvalues [-1.72015325  8.72015325]\n",
      "Eigenvectors [[-0.80229293 -0.59693053]\n",
      " [ 0.59693053 -0.80229293]]\n",
      "Non-square matrices don't have eigenvalues or eigenvectors\n"
     ]
    }
   ],
   "source": [
    "##Answer to question 1.1.2e\n",
    "matrices = [M, P]\n",
    "print(\"For M and P\")\n",
    "for X in matrices:      \n",
    "    eigenvalues, eigenvectors = np.linalg.eig(X)\n",
    "    print(\"Eigenvalues\", eigenvalues)\n",
    "    print(\"Eigenvectors\", eigenvectors)\n",
    "\n",
    "print(\"Non-square matrices don't have eigenvalues or eigenvectors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intermezzo: proper scientific plotting practices \n",
    "\n",
    "**In this course and many others** you will be asked to make a lot of plots. If you've ever read an academic paper, you'll have noticed that besides axis labels, titles and legends, these also contain a figure description *for each plot*. The idea is that you can 'read' a figure without skimming through the text for the explanation. So these figure descriptions should contain\n",
    "\n",
    "1. A description in natural language explaining what we're looking at,\n",
    "2. references to the axis labels if these are not clear immediately, and\n",
    "3. provide a short answer to the question that it belongs to. \n",
    "\n",
    "### Examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure 1: an example of a simple plot. X axis shows the index of each element, the Y axis shows increasing numbers.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure 2: an example of a slightly more complex plot, where we explicitely set the values on the X axis. X axis shows the index of each element, the Y axis shows increasing numbers.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x800 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure 3: an example of a complex plot, which showcases some neat pretty stuff that matplotlib can do! Seaborn is a library that you can use to make your plots look nicer. Subplots are used to create multiple plots within the same figure. First I plotted some random black dots, and then I used the bar functions to plot the same information but more complicated. imshow can be used to plot your array as an image for easy inspection. Here, I created an image of blobs using random numbers and a gaussian blur filter. Histograms are nice for checking distributions, for instance, the distribution of gray values in an image containing blobs!\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "numbers = np.arange(100,1001,100)\n",
    "\n",
    "# Simple plot\n",
    "\n",
    "plt.plot(numbers)\n",
    "plt.xlabel('x axis')\n",
    "plt.ylabel('y axis')\n",
    "plt.title('Numbers')\n",
    "plt.show()\n",
    "print('Figure 1: an example of a simple plot. X axis shows the index of each element, the Y axis shows increasing numbers.')\n",
    "\n",
    "# a little more complex plot\n",
    "\n",
    "indices = np.arange(5,15)\n",
    "plt.scatter(indices,numbers)\n",
    "plt.xlabel('x axis')\n",
    "plt.ylabel('y axis')\n",
    "plt.title('Numbers')\n",
    "plt.show()\n",
    "print('Figure 2: an example of a slightly more complex plot, where we explicitely set the values on the X axis. X axis shows the index of each element, the Y axis shows increasing numbers.')\n",
    "\n",
    "\n",
    "# an incredibly unnecessary complex plot\n",
    "import seaborn as sns # nicer graphics\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "fig,ax = plt.subplots(3,2,figsize=(8,8)) # create 3 rows of 2 columns of subplots\n",
    "ax = ax.ravel()\n",
    "\n",
    "x = np.random.normal(0.1, 1,10) #10 numbers with a mean of 0.1 and a sigma of 1\n",
    "y = np.random.normal(1, 0.1,10) #10 numbers with a mean of 1 and a sigma of 0.1\n",
    "\n",
    "ax[0].plot(x,y,'k.') # k means black and . means it should plot dots. Similarly, 'r-' results in a red line and \n",
    "                    # 'b--' would result in a blue checkered line.\n",
    "ax[0].set_title('Random black dots using x and y as coords')\n",
    "ax[0].set_ylabel('Row 0 of subplots')\n",
    "ax[1].bar(range(0,10),x,color='orange') #the first argument tells plt where to place the bars, so range(0,10) just puts them on 0,..,9\n",
    "ax[1].set_title('Vertical bars of x values')\n",
    "\n",
    "ax[2].barh(range(0,10),y,color='darkblue')\n",
    "ax[2].set_title('Horizontal bars of y values')\n",
    "ax[2].set_ylabel('Row 1 of subplots')\n",
    "from scipy import ndimage \n",
    "\n",
    "im = np.zeros((28, 28)) # creates an 28x28 array of zeros\n",
    "points = 28 * np.random.random((2, 3 ** 2)) # creates 28 random (x,y) pairs that we will use as indices\n",
    "im[(points[0]).astype(np.int), (points[1]).astype(np.int)] = 1 # sets the value at those indices to 1\n",
    "im = ndimage.gaussian_filter(im, sigma=28 / (4. * 3)) # puts the array through an image filter that \n",
    "                                                        # blurs the 0's and 1's together\n",
    "blobs = (im > im.mean())*255 # seperates them back into 0's and 1's after blurring \n",
    "\n",
    "ax[3].imshow(blobs,cmap='gray') # plots the array as an image, where each pixel corresponds to a 0 or 1 in our array\n",
    "ax[3].set_title('Blobs in black and white')\n",
    "\n",
    "ax[4].hist(im.ravel(), bins=12,color='green',rwidth=0.9) # plot the gray values from the array in a histogram with 12 bins\n",
    "ax[4].set_title('Distribution of grayvalues')\n",
    "ax[4].set_ylabel('Row 2 of subplots')\n",
    "ax[4].set_xlabel('Column 0 of subplots')\n",
    "ax[5].hist(im.ravel(),bins=12, cumulative=True, color='orange',rwidth=0.9,alpha=0.8,label='summed') # plot a see through \n",
    "                                                                                # cumulative histogram with alpha\n",
    "ax[5].hist(im.ravel(), bins=12,color='green',rwidth=0.9,alpha=0.7,label='values') # plot the gray values from the array in a histogram with 12 bins\n",
    "ax[5].set_title('(Cumulative) Distribution of grayvalues')\n",
    "ax[5].legend()\n",
    "ax[5].set_xlabel('Column 1 of subplots')\n",
    "plt.tight_layout() # makes sure everything fits without overlapping -- try running this cell without this to see the effect\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print('Figure 3: an example of a complex plot, which showcases some neat pretty stuff that matplotlib can do! Seaborn is a library that you can use to make your plots look nicer. Subplots are used to create multiple plots within the same figure. First I plotted some random black dots, and then I used the bar functions to plot the same information but more complicated. imshow can be used to plot your array as an image for easy inspection. Here, I created an image of blobs using random numbers and a gaussian blur filter. Histograms are nice for checking distributions, for instance, the distribution of gray values in an image containing blobs!')\n",
    "sns.reset_orig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Principal Component Analysis\n",
    "\n",
    "**1.2.1** many experimenters have a habit of using Microsoft Excel as their tool to record measurements from experiments. Fortunately Python can read Excel files. Various methods exist, of which the use of the Python library Pandas is arguably one of the easiest for the purpose of Data Mining.\n",
    "\n",
    "The data used in this exercise is based on data from a chemical sensor obtained from the NanoNose project[1]. The data contains 8 sensors, named by the letters A-H, measuring the concentration of Water, Ethanol, Acetone, Heptane and Pentanol injected into a small gas chamber. The data will be represented in matrix form such that each column contains the 8 sensor measurements (i.e., sensor A-H) of the various compounds injected into the gas chamber.\n",
    "> a. (0.2 points) Inspect the nanonose.xls file in the Data folder and make sure you understand how the data is stored in Excel.\n",
    "\n",
    "> *Load the data in python using the Pandas library (use the `read_excel()` function). Make sure you read some of the Pandas documentation! Especially (column) slicing, (row) indexing and dropping are useful commands to get the correct data here.*\n",
    "\n",
    "> *Make sure to inspect the data first. **You should cut out some rows and columns! You can easily inspect the structure of the Pandas dataframe by printing the `head()` function.***\n",
    "\n",
    "> *You should see the 8 columns named A-H and the first 5 rows by printing `head()`.*\n",
    "\n",
    "> *Finally use the `.values` function to cast the Pandas dataframe to a NumPy array called **X**. *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'nanonose.xls'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-5d81824ecf04>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#The nanonose.xls file was moved to the directory of the Assignment_1.ipynb file for convenience\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'nanonose.xls'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\PythonNCo\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    175\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\PythonNCo\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    175\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\PythonNCo\\lib\\site-packages\\pandas\\io\\excel.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, **kwds)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     return io.parse(\n",
      "\u001b[1;32mF:\\PythonNCo\\lib\\site-packages\\pandas\\io\\excel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, io, **kwds)\u001b[0m\n\u001b[0;32m    392\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m             raise ValueError('Must explicitly set engine if not passing in'\n",
      "\u001b[1;32mF:\\PythonNCo\\lib\\site-packages\\xlrd\\__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[1;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile_contents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# a ZIP file\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'nanonose.xls'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#The nanonose.xls file was moved to the directory of the Assignment_1.ipynb file for convenience\n",
    "df = pd.read_excel('nanonose.xls')\n",
    "M = df.as_matrix()\n",
    "print (M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> b. (0.3 points) The data resides in what can be seen as an 8-dimensional space. Each dimension (column), corresponds to one of the 8 NanoNose sensors. Multidimensional (>3) data is hard to visualize, as we are unable to plot that many dimensions simultaneously.\n",
    "\n",
    "> Using the `matplotlib.pyplot` library, plot the attributes A and B against each other. After you have plotted A against B, also plot a few other combinations of attributes. Plot at least 4 different combinations. \n",
    "\n",
    "> *Do not forget to label your axes and add a figure description!*\n",
    "\n",
    "> NOTE: If you want to plot inside the Jupyter notebook without calling `plt.show()` after each plot, use the following command after you imported the `matplotlib.pyplot` library: \n",
    "*%matplotlib inline* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "plt.figure(1)\n",
    "\n",
    "A = df[['A']]\n",
    "B = df[['B']]\n",
    "C = df[['C']]\n",
    "D = df[['D']]\n",
    "E = df[['E']]\n",
    "F = df[['F']]\n",
    "G = df[['G']]\n",
    "H = df[['H']]\n",
    "\n",
    "\n",
    "plt.plot(A,B , 'ro', label = \"A against B\")\n",
    "\n",
    "plt.title(\"A plotted against B\")\n",
    "plt.xlabel('A')\n",
    "plt.ylabel('B')\n",
    "\n",
    "\n",
    "plt.figure(2)\n",
    "\n",
    "plt.plot(A,C,'ro')\n",
    "\n",
    "plt.title(\"A plotted against C\")\n",
    "plt.xlabel('A')\n",
    "plt.ylabel('C')\n",
    "\n",
    "\n",
    "plt.figure(3)\n",
    "\n",
    "plt.plot(C,D,'ro')\n",
    "\n",
    "plt.title(\"C plotted against D\")\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('D')\n",
    "\n",
    "\n",
    "plt.figure(4)\n",
    "\n",
    "plt.plot(D,C, 'ro')\n",
    "\n",
    "plt.title(\"D plotted against C\")\n",
    "plt.xlabel('D')\n",
    "plt.ylabel('C')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1.2.2 Principal Component Analysis, more commonly known as PCA, can be used to visualize high dimensional data. \n",
    "\n",
    "> a. (1 point) Explain what PCA is and when it can be used. Make sure to provide an in-depth explanation and note what the drawbacks and limitations are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "\n",
    "_write your answer to 1.2.2 here_\n",
    "\n",
    "Principle component analaysis is a technique used for dimensionality reduction.\n",
    "In essence a new coordinate system is found, in which the origin is on the mean if the values and its axis are the principle components, these principle components are the directions of largest variance and ar orthogonal to each other. After this is done the datapoints can be projected onto the coordinate system of the first couple principle components.\n",
    "\n",
    "It can be used to reduce the number of variables in situations where it is difficult identify the variables to remove. A real-life example could be trying to predict the total number of sales a large retailer might have. In this case, there is a lot of data to consider like for example: Purchasing power, target demographic, advertisement/discounts, inventory expansion and competition. Using PCA to remove the dimensionality makes data faster to process and interpret.\n",
    "\n",
    "That said there are drawbacks most importantly that PCA can only help in finding linear relations it helps find the direction of this linear data using the orthogonal components, however this obviously does not work for data that is not linearly related. A good example of non-linearly related data is the amount of people helping to do a single task and the time the job takes.\n",
    "Other drawbacks are that extreme noise might cause PCA to suggest that the noise is the most important relation in the data. And like other dimensionality reduction techniques, removing dimensions makes independant variables less interpretable.\n",
    "\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply PCA we must first mean center the data. Mean centering means that the mean value for an attribute (i.e. a column) is subtracted from all values for that attribute. \n",
    "\n",
    "> b. (0.5 points) Why do we first need to mean center the data before applying PCA?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "The components calculated in PCA are based on the deviation of the data points, this means that points with higher deviation have a higher weight in the calculation. Essentially when we mean center the data, we lower the standard deviation of our data points. This means that in our calculation all our data points will have the same weight, giviing a much better PCA projection.\n",
    "\n",
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, applying PCA comes down to a series of matrix operations, this is useful, as matrix operations can be applied with little effort and can be computed in relatively little time.\n",
    "\n",
    "The given data **X** must first be mean centered. This can be easily done by calculating a row vector **μ** containing the mean values of each attribute. Then you can subtract **μ** from **X** (**Y** = **X** - **μ**, where **μ** is subtracted from every row.).\n",
    "\n",
    "Then, the Singular Value Decomposition (or SVD) of **Y**, the now mean centered data, can be calculated. **Y** = **USV**<sup>T</sup>. In practice, this is often done using the `numpy.linalg.svd()` function.\n",
    "\n",
    "Using SVD on **Y** yields 3 matrices **U**, **S** and **V**<sup>T</sup>. These are used to project the data onto specific Principal Components (PCs). \n",
    "\n",
    "The entire dataset can be projected onto the Principal Components by multiplying **Z** = **Y\\*V**, where **Z** indicates the projected data, and **Z[:,0]** indicates the data projected onto the first PC. Alternatively, one could project onto just a subset of all the PCs by indexing in the multiplication. For example: **Z** = **Y\\*V[:,0]** would also yield the projection of the data onto the first PC.\n",
    "\n",
    "_Note that for matrices, the notation **Y\\*V** denotes the `dot` product between **Y** and **V**!_\n",
    "\n",
    "> c. (1 point)  Apply PCA (using the aforementioned method) on the Nanonose data and visualize a scatterplot of the projection of the data onto the first two PCs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']\n",
    "u = np.array([]) # Mean row vector \n",
    "for a in columns:\n",
    "    col = df[[a]]\n",
    "    u = np.append(u, np.mean(col))\n",
    "\n",
    "X = np.delete(M, 0, 1)  \n",
    "X = np.delete(X, 0, 1)  \n",
    "X = np.delete(X, 0, 1)\n",
    "X = np.delete(X, 0, 0) # Matrix of only observation\n",
    "\n",
    "Y = X - u # Mean centered matrix\n",
    "\n",
    "# For some reason numpy's svd function did not like the matrix constructed here. \n",
    "# Therefore we also did the calculations in 'matrixY.xlsx' This is identical to the matrix above.\n",
    "impY = pd.read_excel('matrixY.xlsx') #This is simply the matrix reimported so columns A-H and mean centered\n",
    "Y = impY.as_matrix()\n",
    "\n",
    "u, s, vh = np.linalg.svd(Y)\n",
    "pca1 = np.dot(Y, vh[:,1]) \n",
    "pca2 = np.dot(Y, vh[:,2]) \n",
    "\n",
    "# Plotting\n",
    "\n",
    "plt.plot(pca1,pca2 , 'ro', label = \"PCA\")\n",
    "plt.xlabel('pca1')\n",
    "plt.ylabel('pca2')\n",
    "plt.title(\"Projection of the data onto the first two PCs\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> d. (1 point) Alternatively, one could use EigenValue Decomposition, EVD, instead of SVD. What are the similarities and differences between SVD and EVD? Can both be applied in each case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Similarities\n",
    "Both EVD and SVD are factorizations of matrices, this means the are rotatations of coordinate systems and have independent scaling along each axis. In fact SVD is the generalization of SVD on non-square matrices. In fact the left and right singular vectors of SVD are both orthonormal eigenvectors.\n",
    "\n",
    "Differences\n",
    "As said above the SVD vectors are orthonormal, meaning that they represent simple rotations or flips this isn't the case in EVD. On the other hand EVD first and last diagnonal matrices (U in the slides) are each other's inverse, this is not the case in SVD. Lastly in SVD the middle diagonal matrix (capital sigma in the slides) can only be 0 or a positive real number. In EVD the middle diagonal matrix (capital lambda in the slides) can be negative and complex.\n",
    "\n",
    "Applicability\n",
    "Eigenvalue decomposition can only applied to square matrices, where SVD can be done on any matrix.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA attempts to explain as much of the variance in data with as few PCs as possible. The variance explained by each of the PCs **m** can be calculated using the following formula: \n",
    "$$\\rho_m = 1 - \\frac{\\|{Y} - {u}_m s_{mm} {v}_m^T\\|^2_F}{\\|{Y}\\|^2_F} = \\frac{s_{mm}^2}{\\displaystyle \\sum_{m'=1}^M s^2_{m'm'}}$$\n",
    "\n",
    "Which indicates that the variation $\\rho$ for a given **m** can be calculated by dividing the squared singular value of component **m** by the sum of all squared singular values. \n",
    "> e. (1 point) Calculate the row vector $\\rho$ containing all values of $\\rho$ for all PCs **m**. Create a bar plot with the variance explained on the Y axis and the number of the PC on the X axis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gar, S, bage = np.linalg.svd(Y)\n",
    "\n",
    "total = 0\n",
    "for tot in S:\n",
    "    total = total + (tot**2)\n",
    "\n",
    "p = np.array([])\n",
    "for s in S:\n",
    "    p = np.append(p, ((s**2)/(total)))\n",
    "plt.bar([1,2,3,4,5,6,7,8],p)\n",
    "plt.xlabel('PC')\n",
    "plt.ylabel('variance')\n",
    "plt.title(\"Variance of PCs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> f. (0.5 points) How much of the variance is explained by the first three PCs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "for var in range(2):\n",
    "    total = total + p[var]\n",
    "    \n",
    "print (total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns of **V** indicate the exact projection of the data onto the PCs. In a way, a PC is nothing other than a linear combination of the original attributes. \n",
    "> g. (0.5 points) Which attributes are primarily represented by the first PC? What would cause an observation to have a large negative/positive projection onto the second principal component?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj1 = vh[:,1] \n",
    "proj2 = vh[:,2]\n",
    "print(proj1)\n",
    "print(proj2)\n",
    "\n",
    "plt.figure(11)\n",
    "plt.title(\"A against proj1\")\n",
    "plt.xlabel('cell No.')\n",
    "plt.ylabel('value')\n",
    "plt.plot(A, pca1, 'ro')\n",
    "\n",
    "plt.figure(12)\n",
    "\n",
    "plt.title(\"B plot\")\n",
    "plt.xlabel('cell No.')\n",
    "plt.ylabel('value')\n",
    "plt.plot(B, 'ro')\n",
    "plt.figure(13)\n",
    "\n",
    "plt.title(\"C plot\")\n",
    "plt.xlabel('cell No.')\n",
    "plt.ylabel('value')\n",
    "plt.plot(C, 'ro')\n",
    "plt.figure(14)\n",
    "\n",
    "plt.title(\"D plot\")\n",
    "plt.xlabel('cell No.')\n",
    "plt.ylabel('value')\n",
    "plt.plot(D, 'ro')\n",
    "\n",
    "plt.figure(15)\n",
    "\n",
    "plt.title(\"E plot\")\n",
    "plt.xlabel('cell No.')\n",
    "plt.ylabel('value')\n",
    "plt.plot(E, 'ro')\n",
    "\n",
    "plt.figure(16)\n",
    "\n",
    "plt.title(\"F plot\")\n",
    "plt.xlabel('cell No.')\n",
    "plt.ylabel('value')\n",
    "plt.plot(F, 'ro')\n",
    "\n",
    "plt.figure(17)\n",
    "\n",
    "plt.title(\"G plot\")\n",
    "plt.xlabel('cell No.')\n",
    "plt.ylabel('value')\n",
    "plt.plot(G, 'ro')\n",
    "\n",
    "plt.figure(18)\n",
    "\n",
    "plt.title(\"H plot\")\n",
    "plt.xlabel('cell No.')\n",
    "plt.ylabel('value')\n",
    "plt.plot(H, 'ro')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "_write your answer to 1.2.2 here_\n",
    "\n",
    "-----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Similarity measures\n",
    "\n",
    "We will use a subset of the data on wild faces described by Berg in 2005 transformed to a total\n",
    "of 1000 grayscale images of size 40x40 pixels, we will attempt to find faces in the\n",
    "data base that are the most similar to a given query face. To measure similarity we\n",
    "will consider the following measures: SMC, Jaccard, Cosine, ExtendedJaccard, and\n",
    "Correlation. These measures of similarity are described in *Introduction to Data Mining*, page 73-77 and are given by\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\\textrm{SMC}({x},{y}) & = & \\frac{\\textrm{Number of matching attribute values}}{\\textrm{Number of attributes}} \\\\\n",
    "\\textrm{Jaccard}({x},{y}) & = & \\frac{\\textrm{Number of matching presences}}{\\textrm{Number of attributes not involved in 00 matches}} \\\\\n",
    "\\textrm{Cosine}({x},{y}) & = & \\frac{{x}^T {y}}{\\|{x}\\| \\|{y}\\|} \\\\\n",
    "\\textrm{ExtendedJaccard}({x},{y}) & = & \\frac{{x}^T {y}}{\\|{x}\\|^2 + \\|{y}\\|^2 - {x}^T {y}} \\\\\n",
    "\\textrm{Correlation}({x},{y}) & = & \\frac{\\textrm{cov}({x},{y})}{\\textrm{std}({x}) \\textrm{std}({y})}\n",
    "\\\\\n",
    "\\end{eqnarray*}\n",
    "<br>where $\\textrm{cov}({x},{y})$ denotes the covariance between ${x}$ and ${y}$ and $\\textrm{std}({x})$ denotes the standard deviation of ${x}$.\n",
    "\n",
    "Notice that the SMC and Jaccard similarity measures only are defined for binary data, i.e., data that takes values in $\\{0,1\\}$. As the data we analyze is non-binary, the script will transform the data to be binary when calculating these two measures of similarity by setting\n",
    "\n",
    "$$x_i = \\left\\{ \\begin{array}{ll} 0 & \\textrm{if~} x_i < \\textrm{median}({x}) \\\\\n",
    "                                1 & \\textrm{otherwise.} \\end{array} \\right.$$\n",
    "                                \n",
    "### 1.3.1\n",
    "> a) (0.5 points) Inspect and run the simfaces function from the Toolbox. The function loads the CBCL face database, computes the similarity between a selected query image and all others, and display the query image, the 5 most similar images, and the 5 least similar images. The value of the used similarity measure is shown below each image. Try changing the query image and the similarity measure and see what happens. Which similarity measures produce similar results? Which one gives the best result? Why?\n",
    "\n",
    "> Give a quick overview of the settings (image number and similarity measure) for each time you run the script. Remember to leave results open!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Toolbox.simfaces import simfaces\n",
    "\n",
    "measures = ['smc', 'jaccard', 'cosine', 'extendedjaccard', 'correlation']\n",
    "for c in range(4):\n",
    "    for measure in measures:\n",
    "        print (measure)\n",
    "        simfaces((c+1),measure)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "\n",
    "SMC and jaccard give similar results in the \"most similar faces\", especially in image 1 and 3. This might be becuase they both use a binary representation of the data.\n",
    "\n",
    "Correlation seems to give the best results on average, as its least similar pictures often contains non-face pictures or improperly cropped pictures. With its most similar pictures often being most similar in head location, head orientation, skin tone and expression.\n",
    "\n",
    "----\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> b) (0.75 points) We will investigate how scaling and translation impact the following three\n",
    "similarity measures: Cosine, ExtendedJaccard, and Correlation. Let **x** and **y** be two small vectors of the same size. Let $\\alpha$ and $\\beta$ be two constants. You can generate these randomly or set them as you see fit. Using Python, calculate the following similarity measures, and check if the statements below are correct.\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "\\textrm{Cosine}(\\alpha{x},{y}) & = & \\textrm{Cosine}({x},{y}) \\\\\n",
    "\\textrm{ExtendedJaccard}(\\alpha{x},{y}) & = & \\textrm{ExtendedJaccard}({x},{y}) \\\\\n",
    "\\textrm{Correlation}(\\alpha{x},{y}) & = & \\textrm{Correlation}({x},{y}) \\\\\n",
    "\\textrm{Cosine}(\\beta + {x},{y}) & = & \\textrm{Cosine}({x},{y}) \\\\\n",
    "\\textrm{ExtendedJaccard}(\\beta + {x},{y}) & = & \\textrm{ExtendedJaccard}({x},{y}) \\\\\n",
    "\\textrm{Correlation}(\\beta + {x},{y}) & = & \\textrm{Correlation}({x},{y})\n",
    "\\end{eqnarray*}\n",
    "\n",
    "> Type `help similarity` or study `similarity.py` to learn about the function that is used to compute the similarity measures. Do not forget to also import similarity.py!\n",
    "\n",
    "> Even though a similarity measure is theoretically invariant e.g.\\ to scaling, it might not be exactly invariant numerically.\n",
    "\n",
    "> Do not forget to also provide an explanation in addition to the calculations!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 500\n",
    "b = 1500\n",
    "x = np.array([6, 7, 8 ,9, 10 ,11, 12])\n",
    "y = np.array([3, 7, 11 ,15, 19 ,23, 27])\n",
    "\n",
    "def xty(x, y):  # The dot product of x transposed, with y\n",
    "    return np.dot(x.transpose(), y)\n",
    "\n",
    "def covariance(x, y):  # Covariance of 2 vectors as explained in the slides\n",
    "    total = 0\n",
    "    for k in range(len(x-1)):\n",
    "        total = total + ((x[k]-(np.mean(x)))*(y[k]-(np.mean(y))))\n",
    "    return ((1/len(x))*total)\n",
    "        \n",
    "def cosine(x, y):  # Cosine function in python\n",
    "    return (xty(x, y))/(np.linalg.norm(x)*np.linalg.norm(y))\n",
    "\n",
    "def extendedjaccard(x, y):  # Extended Jaccard function in python\n",
    "    return ((xty(x, y))/((np.linalg.norm(x)**2)+(np.linalg.norm(y)**2)-(xty(x, y))))\n",
    "    \n",
    "def correlation(x, y):  # Correlation function in python\n",
    "    return (covariance(x, y))/(np.std(x)*np.std(x))\n",
    "   \n",
    "measures = [cosine, extendedjaccard, correlation]\n",
    "\n",
    "\n",
    "print (\"Scaling equalities: \")  # Prints if function is invariant to scaling\n",
    "for measure in measures:\n",
    "    print(measure.__name__)\n",
    "    print (measure (x, y) == measure (a*x, y))\n",
    "\n",
    "print (\"\\nTranslation equalities: \")  # Prints if function is invariant to translation\n",
    "for measure in measures:\n",
    "    print(measure.__name__)\n",
    "    print (measure (x, y) == measure ((b+x), y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "For the statements, only 2 are correct. Only cosine is invariant to scaling and only correlation is invariant to translation.\n",
    "\n",
    "This was computed by translating each function to python, then executing them against their scaled on translated counterparts, and checking the resulting equalities.\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "790px",
    "left": "827px",
    "right": "20px",
    "top": "64px",
    "width": "800px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
